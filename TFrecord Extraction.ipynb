{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFrecord Extraction Blog.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "s9s_oLeydCiA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b36C-FoMIM-u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# TFrecord Extraction\n",
        "\n",
        "\n",
        "We will load a tfrecord dataset and get the data out to use them with some other framework, for example TensorFlow on Julia.\n",
        "\n",
        "##Prepare Packages and Parse Function"
      ]
    },
    {
      "metadata": {
        "id": "Z2vRJCmjIbPu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "9afad190-3019-41e6-a6e8-fef6f6aa3d19"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import collections\n",
        "import io\n",
        "import math\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from IPython import display\n",
        "from sklearn import metrics\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "train_url = 'https://storage.googleapis.com/mledu-datasets/sparse-data-embedding/train.tfrecord'\n",
        "train_path = tf.keras.utils.get_file(train_url.split('/')[-1], train_url)\n",
        "test_url = 'https://storage.googleapis.com/mledu-datasets/sparse-data-embedding/test.tfrecord'\n",
        "test_path = tf.keras.utils.get_file(test_url.split('/')[-1], test_url)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/mledu-datasets/sparse-data-embedding/train.tfrecord\n",
            "41631744/41625533 [==============================] - 0s 0us/step\n",
            "41639936/41625533 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/mledu-datasets/sparse-data-embedding/test.tfrecord\n",
            "40689664/40688441 [==============================] - 0s 0us/step\n",
            "40697856/40688441 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lNIsLhoMIhy3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _parse_function(record):\n",
        "  \"\"\"Extracts features and labels.\n",
        "  \n",
        "  Args:\n",
        "    record: File path to a TFRecord file    \n",
        "  Returns:\n",
        "    A `tuple` `(labels, features)`:\n",
        "      features: A dict of tensors representing the features\n",
        "      labels: A tensor with the corresponding labels.\n",
        "  \"\"\"\n",
        "  features = {\n",
        "    \"terms\": tf.VarLenFeature(dtype=tf.string), # terms are strings of varying lengths\n",
        "    \"labels\": tf.FixedLenFeature(shape=[1], dtype=tf.float32) # labels are 0 or 1\n",
        "  }\n",
        "  \n",
        "  parsed_features = tf.parse_single_example(record, features)\n",
        "  \n",
        "  terms = parsed_features['terms'].values\n",
        "  labels = parsed_features['labels']\n",
        "\n",
        "  return  {'terms':terms}, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r0KG0RNkb2J8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training Data\n",
        "\n",
        "We start with the training data."
      ]
    },
    {
      "metadata": {
        "id": "IjCsierOIlT_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create the Dataset object.\n",
        "ds = tf.data.TFRecordDataset(train_path)\n",
        "# Map features and labels with the parse function.\n",
        "ds = ds.map(_parse_function)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KVwiTl5eInYd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Make a one shot iterator\n",
        "n = ds.make_one_shot_iterator().get_next()\n",
        "sess = tf.Session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ILb2K8qznWfG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Direct meta-information on the number of datasets in a ``tfrecord`` file is unfortunately not available. We use the following nice hack to get the total number of entries by iterating over the whole dataset. "
      ]
    },
    {
      "metadata": {
        "id": "J_1tXFDvnQLW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6dcf978d-9e62-4464-d112-a62429eeb9b7"
      },
      "cell_type": "code",
      "source": [
        "sum(1 for _ in tf.python_io.tf_record_iterator(train_path))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "lG2OTnlxbdgi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now, we create two vectors to store the output labels and features. Looping over the ``tfrecord``-dataset extracts the entries."
      ]
    },
    {
      "metadata": {
        "id": "TCGFkmQdJjZ0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "output_features=[]\n",
        "output_labels=[]\n",
        "\n",
        "for i in range(0,24999):\n",
        "  value=sess.run(n)\n",
        "  output_features.append(value[0]['terms'])\n",
        "  output_labels.append(value[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4QJINDWHSVPy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Export to File\n",
        "\n",
        "We create a file to export using the h5py package."
      ]
    },
    {
      "metadata": {
        "id": "crZXrT6KOPVD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import h5py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ulLIGupVO-wM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dt = h5py.special_dtype(vlen=str)\n",
        "\n",
        "h5f = h5py.File('train_data.h5', 'w')\n",
        "h5f.create_dataset('output_features', data=output_features, dtype=dt)\n",
        "h5f.create_dataset('output_labels', data=output_labels)\n",
        "h5f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KupXUjS-b0NE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Test Data\n",
        "\n",
        "We do a similar action on the test data."
      ]
    },
    {
      "metadata": {
        "id": "tkxCqeH_bzqp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create the Dataset object.\n",
        "ds = tf.data.TFRecordDataset(test_path)\n",
        "# Map features and labels with the parse function.\n",
        "ds = ds.map(_parse_function)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KKgsxkyIcNln",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n = ds.make_one_shot_iterator().get_next()\n",
        "sess = tf.Session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "13GV5BjzbV5k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The total number of datasets is"
      ]
    },
    {
      "metadata": {
        "id": "WgoUMbt3bZKj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "80173c90-4cf4-4a1b-f5a2-163d1a92f884"
      },
      "cell_type": "code",
      "source": [
        "sum(1 for _ in tf.python_io.tf_record_iterator(test_path))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "8hqCiRuMbzZv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "output_features=[]\n",
        "output_labels=[]\n",
        "\n",
        "for i in range(0,24999):\n",
        "  value=sess.run(n)\n",
        "  output_features.append(value[0]['terms'])\n",
        "  output_labels.append(value[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IOtz08uKcD-i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Export to file"
      ]
    },
    {
      "metadata": {
        "id": "XVhctiY-cOUz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dt = h5py.special_dtype(vlen=str)\n",
        "\n",
        "h5f = h5py.File('test_data.h5', 'w')\n",
        "h5f.create_dataset('output_features', data=output_features, dtype=dt)\n",
        "h5f.create_dataset('output_labels', data=output_labels)\n",
        "h5f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BpOaFRMRSXWa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Google Drive Export\n",
        "\n",
        "Finally, we export the two files containing the training and test data to Google Drive. If necessary, intall the PyDrive package using ``!pip install -U -q PyDrive``. The folder-id is the string of letters and numbers that can be seen in your browser URL after ``https://drive.google.com/drive/u/0/folders/`` when accessing the desired folder."
      ]
    },
    {
      "metadata": {
        "id": "5S4tUjTfTQHe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2Q5uOqhlQJZE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default() \n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# PyDrive reference:\n",
        "# https://googledrive.github.io/PyDrive/docs/build/html/index.html"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "REoT58sUS4Kw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Adjust the id to the folder of your choice in Google Drive\n",
        "# Use `file = drive.CreateFile()` to write to root directory\n",
        "file = drive.CreateFile({'parents':[{\"id\": \"insert_folder_id\"}]})\n",
        "file.SetContentFile('train_data.h5')\n",
        "file.Upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WGwibnA8TuDe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Adjust the id to the folder of your choice in Google Drive\n",
        "# Use `file = drive.CreateFile()` to write to root directory\n",
        "file = drive.CreateFile({'parents':[{\"id\": \"insert_folder_id\"}]})\n",
        "file.SetContentFile('test_data.h5')\n",
        "file.Upload()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}